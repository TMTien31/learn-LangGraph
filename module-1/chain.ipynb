{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbf2458",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-1/chain.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58238466-lesson-4-chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee55d3da-c53a-4c76-b46f-8e0d602e072e",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "## Review\n",
    "\n",
    "We built a simple graph with nodes, normal edges, and conditional edges.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's build up to a simple chain that combines 4 [concepts](https://python.langchain.com/v0.2/docs/concepts/):\n",
    "\n",
    "* Using [chat messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as our graph state\n",
    "* Using [chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) in graph nodes\n",
    "* [Binding tools](https://python.langchain.com/v0.2/docs/concepts/#tools) to our chat model\n",
    "* [Executing tool calls](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling) in graph nodes \n",
    "\n",
    "![Screenshot 2024-08-21 at 9.24.03 AM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dd607b08df5e1101_chain1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ac2d0-c7b0-4a20-86e5-4b6ed15ec20e",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "Chat models can use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages), which capture different roles within a conversation. \n",
    "\n",
    "LangChain supports various message types, including `HumanMessage`, `AIMessage`, `SystemMessage`, and `ToolMessage`. \n",
    "\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call. \n",
    "\n",
    "Let's create a list of messages. \n",
    "\n",
    "Each message can be supplied with a few things:\n",
    "\n",
    "* `content` - content of the message\n",
    "* `name` - optionally, a message author \n",
    "* `response_metadata` - optionally, a dict of metadata (e.g., often populated by model provider for `AIMessages`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "866b5321-a238-4a9e-af9e-f11a131b5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\",name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca48df0-b639-4ff1-a777-ffe2185d991e",
   "metadata": {},
   "source": [
    "## Chat Models\n",
    "\n",
    "[Chat models](https://python.langchain.com/v0.2/docs/concepts/#chat-models) can use a sequence of message as input and support message types, as discussed above.\n",
    "\n",
    "There are [many](https://python.langchain.com/v0.2/docs/concepts/#chat-models) to choose from! Let's work with OpenAI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4f787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\", temperature=0, api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae53d4-14f5-4bf3-a953-cc465240f5b5",
   "metadata": {},
   "source": [
    "We can load a chat model and invoke it with out list of messages.\n",
    "\n",
    "We can see that the result is an `AIMessage` with specific `response_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b99ad4-5753-49d3-a916-a9e949722c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(messages)\n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d60338-c892-4d04-a83f-878de4a76a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Excellent question! Orcas, also known as killer whales, are magnificent creatures. In the US, the best places to see them depend on what kind of experience you're looking for. Here's a breakdown:\\n\\n**For the best chance of seeing Orcas in the wild, I'd recommend the following:**\\n\\n*   **Puget Sound, Washington State:** This is arguably the most famous and reliable location.\\n    *   **Why it's good:** This area is home to the Southern Resident Orca population, a critically endangered group. Whale watching tours are very common and well-established, with a high success rate during the season. You can often see them from land as well, especially at places like Lime Kiln Point State Park on San Juan Island.\\n    *   **Best Time to Visit:** Generally, the best time is from **late spring (May/June) through early fall (September/October)**. The whales are often present in the area during these months, following salmon runs.\\n    *   **Considerations:** The Southern Residents are a specific population, and their presence is not guaranteed. Also, be aware of the regulations in place to protect them, such as vessel speed limits and distance requirements.\\n\\n*   **The San Juan Islands, Washington State:** This is part of the Puget Sound area, but it deserves a special mention.\\n    *   **Why it's good:** The islands offer a beautiful setting for whale watching. You can take boat tours from various towns like Friday Harbor on San Juan Island, or Anacortes. You can also kayak, though you must maintain a safe distance from the whales.\\n    *   **Best Time to Visit:** Same as Puget Sound, **late spring to early fall**.\\n    *   **Considerations:** Similar to Puget Sound, the Southern Residents are the primary target, and their presence is not guaranteed.\\n\\n*   **Southeast Alaska:**\\n    *   **Why it's good:** Alaska offers a different experience, with a larger area to explore. You can see both resident and transient (Bigg's) orcas. The scenery is stunning, and you might see other wildlife like humpback whales, bears, and eagles.\\n    *   **Best Time to Visit:** The whale watching season in Alaska is generally from **May to September**.\\n    *   **Considerations:** Tours can be more expensive, and the weather can be unpredictable.\\n\\n**Other Considerations:**\\n\\n*   **Transient (Bigg's) Orcas:** These orcas eat marine mammals (seals, sea lions, etc.) and are found in the same areas as the resident orcas. They are often seen in the same areas as the resident orcas.\\n*   **Research and Conservation:** Consider supporting tour operators that prioritize responsible whale watching practices and contribute to research and conservation efforts.\\n*   **Land-Based Viewing:** If you prefer to stay on land, look for parks and viewpoints that offer good vantage points. Check local websites and visitor centers for information on recent sightings.\\n*   **Tour Operators:** Research and choose reputable tour operators with experienced captains and naturalists. They will have the best knowledge of the area and the whales.\\n\\n**In summary, if you want the best chance of seeing Orcas, I'd recommend focusing on Puget Sound and the San Juan Islands in Washington State during the late spring to early fall months.**\\n\\nDo you have any other questions about Orcas or whale watching? Perhaps you'd like to know more about the different types of Orcas, or the best tour operators in a specific area?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "115e066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excellent question! Orcas, also known as killer whales, are magnificent\n",
      "creatures. In the US, the best places to see them depend on what kind of\n",
      "experience you're looking for. Here's a breakdown:  **For the best chance of\n",
      "seeing Orcas in the wild, I'd recommend the following:**  *   **Puget Sound,\n",
      "Washington State:** This is arguably the most famous and reliable location.\n",
      "*   **Why it's good:** This area is home to the Southern Resident Orca\n",
      "population, a critically endangered group. Whale watching tours are very common\n",
      "and well-established, with a high success rate during the season. You can often\n",
      "see them from land as well, especially at places like Lime Kiln Point State Park\n",
      "on San Juan Island.     *   **Best Time to Visit:** Generally, the best time is\n",
      "from **late spring (May/June) through early fall (September/October)**. The\n",
      "whales are often present in the area during these months, following salmon runs.\n",
      "*   **Considerations:** The Southern Residents are a specific population, and\n",
      "their presence is not guaranteed. Also, be aware of the regulations in place to\n",
      "protect them, such as vessel speed limits and distance requirements.  *   **The\n",
      "San Juan Islands, Washington State:** This is part of the Puget Sound area, but\n",
      "it deserves a special mention.     *   **Why it's good:** The islands offer a\n",
      "beautiful setting for whale watching. You can take boat tours from various towns\n",
      "like Friday Harbor on San Juan Island, or Anacortes. You can also kayak, though\n",
      "you must maintain a safe distance from the whales.     *   **Best Time to\n",
      "Visit:** Same as Puget Sound, **late spring to early fall**.     *\n",
      "**Considerations:** Similar to Puget Sound, the Southern Residents are the\n",
      "primary target, and their presence is not guaranteed.  *   **Southeast Alaska:**\n",
      "*   **Why it's good:** Alaska offers a different experience, with a larger area\n",
      "to explore. You can see both resident and transient (Bigg's) orcas. The scenery\n",
      "is stunning, and you might see other wildlife like humpback whales, bears, and\n",
      "eagles.     *   **Best Time to Visit:** The whale watching season in Alaska is\n",
      "generally from **May to September**.     *   **Considerations:** Tours can be\n",
      "more expensive, and the weather can be unpredictable.  **Other Considerations:**\n",
      "*   **Transient (Bigg's) Orcas:** These orcas eat marine mammals (seals, sea\n",
      "lions, etc.) and are found in the same areas as the resident orcas. They are\n",
      "often seen in the same areas as the resident orcas. *   **Research and\n",
      "Conservation:** Consider supporting tour operators that prioritize responsible\n",
      "whale watching practices and contribute to research and conservation efforts. *\n",
      "**Land-Based Viewing:** If you prefer to stay on land, look for parks and\n",
      "viewpoints that offer good vantage points. Check local websites and visitor\n",
      "centers for information on recent sightings. *   **Tour Operators:** Research\n",
      "and choose reputable tour operators with experienced captains and naturalists.\n",
      "They will have the best knowledge of the area and the whales.  **In summary, if\n",
      "you want the best chance of seeing Orcas, I'd recommend focusing on Puget Sound\n",
      "and the San Juan Islands in Washington State during the late spring to early\n",
      "fall months.**  Do you have any other questions about Orcas or whale watching?\n",
      "Perhaps you'd like to know more about the different types of Orcas, or the best\n",
      "tour operators in a specific area?\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "wrapped_text = textwrap.fill(result.content, width=80) \n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a29654-6b8e-4eda-9cec-22fabb9b8620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_feedback': {'block_reason': 0, 'safety_ratings': []},\n",
       " 'finish_reason': 'STOP',\n",
       " 'model_name': 'gemini-2.0-flash-lite',\n",
       " 'safety_ratings': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4718bd5c-5314-4405-a164-f1fe912ae306",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are useful whenever you want a model to interact with external systems.\n",
    "\n",
    "External systems (e.g., APIs) often require a particular input schema or payload, rather than natural language. \n",
    "\n",
    "When we bind an API, for example, as a tool we given the model awareness of the required input schema.\n",
    "\n",
    "The model will choose to call a tool based upon the natural language input from the user. \n",
    "\n",
    "And, it will return an output that adheres to the tool's schema. \n",
    "\n",
    "[Many LLM providers support tool calling](https://python.langchain.com/v0.1/docs/integrations/chat/) and [tool calling interface](https://blog.langchain.dev/improving-core-tool-interfaces-and-docs-in-langchain/) in LangChain is simple. \n",
    " \n",
    "You can simply pass any Python `function` into `ChatModel.bind_tools(function)`.\n",
    "\n",
    "![Screenshot 2024-08-19 at 7.46.28 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab08dc1c17a7a57f9960_chain2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a942b1",
   "metadata": {},
   "source": [
    "Let's showcase a simple example of tool calling!\n",
    " \n",
    "The `multiply` function is our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "928faf56-1a1a-4c5f-b97d-bd64d8e166d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = llm.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f9dba",
   "metadata": {},
   "source": [
    "If we pass an input - e.g., `\"What is 2 multiplied by 3\"` - we see a tool call returned. \n",
    "\n",
    "The tool call has specific arguments that match the input schema of our function along with the name of the function to call.\n",
    "\n",
    "```\n",
    "{'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9edbe13e-cc72-4685-ac97-2ebb4ceb2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460220de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"b\": 3.0, \"a\": 2.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run--e68b330b-ee82-4cb2-8ab9-0b85a8e91b92-0', tool_calls=[{'name': 'multiply', 'args': {'b': 3.0, 'a': 2.0}, 'id': 'e11610fd-2009-4c7b-8086-7c34a834dfa7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 25, 'output_tokens': 5, 'total_tokens': 30, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a78178cb-fa43-45b5-be5e-5a22bda5a5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'b': 3.0, 'a': 2.0},\n",
       "  'id': 'e11610fd-2009-4c7b-8086-7c34a834dfa7',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c10f9a-2372-486b-9305-55b7c41ecd6e",
   "metadata": {},
   "source": [
    "## Using messages as state\n",
    "\n",
    "With these foundations in place, we can now use [`messages`](https://python.langchain.com/v0.2/docs/concepts/#messages) in our graph state.\n",
    "\n",
    "Let's define our state, `MessagesState`, as a `TypedDict` with a single key: `messages`.\n",
    "\n",
    "`messages` is simply a list of messages, as we defined above (e.g., `HumanMessage`, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3699dd5c-398c-43c7-b496-fd87e55e11ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: list[AnyMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211cba3e-ebba-4b91-a539-1cbc28b4a40e",
   "metadata": {},
   "source": [
    "## Reducers\n",
    "\n",
    "Now, we have a minor problem! \n",
    "\n",
    "As we discussed, each node will return a new value for our state key `messages`.\n",
    "\n",
    "But, this new value [will override](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) the prior `messages` value.\n",
    " \n",
    "As our graph runs, we want to **append** messages to our `messages` state key.\n",
    " \n",
    "We can use [reducer functions](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers) to address this.\n",
    "\n",
    "Reducers allow us to specify how state updates are performed.\n",
    "\n",
    "If no reducer function is specified, then it is assumed that updates to the key should *override it* as we saw before.\n",
    " \n",
    "But, to append messages, we can use the pre-built `add_messages` reducer.\n",
    "\n",
    "This ensures that any messages are appended to the existing list of messages.\n",
    "\n",
    "We simply need to annotate our `messages` key with the `add_messages` reducer function as metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b33eb72-3197-4870-b9a3-0da8056c40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663e574-ba15-46be-a37c-48c8052d693b",
   "metadata": {},
   "source": [
    "Since having a list of messages in graph state is so common, LangGraph has a pre-built [`MessagesState`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)! \n",
    "\n",
    "`MessagesState` is defined: \n",
    "\n",
    "* With a pre-build single `messages` key\n",
    "* This is a list of `AnyMessage` objects \n",
    "* It uses the `add_messages` reducer\n",
    "\n",
    "We'll usually use `MessagesState` because it is less verbose than defining a custom `TypedDict`, as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ab516ee-eab1-4856-8210-99f1fe499672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class MessagesState(MessagesState):\n",
    "    # Add any keys needed beyond messages, which is pre-built \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fff7-60a2-4582-8f12-3a3ab6633d6c",
   "metadata": {},
   "source": [
    "To go a bit deeper, we can see how the `add_messages` reducer works in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23ffea76-16a5-4053-a1bc-91e0101d91dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='fb095451-c5e1-47b6-84b1-9f61ab5aa3c8'),\n",
       " HumanMessage(content=\"I'm looking for information on marine biology.\", additional_kwargs={}, response_metadata={}, name='Lance', id='95d7f725-85fd-4a89-ae8f-d784868b689f'),\n",
       " AIMessage(content='Sure, I can help with that. What specifically are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='00da8987-38b4-4205-b588-753a597a0a1b')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initial state\n",
    "initial_messages = [AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                    HumanMessage(content=\"I'm looking for information on marine biology.\", name=\"Lance\")\n",
    "                   ]\n",
    "\n",
    "# New message to add\n",
    "new_message = AIMessage(content=\"Sure, I can help with that. What specifically are you interested in?\", name=\"Model\")\n",
    "\n",
    "# Test\n",
    "add_messages(initial_messages , new_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485adccc-f262-49dd-af4f-a30e9b6a48e2",
   "metadata": {},
   "source": [
    "## Our graph\n",
    "\n",
    "Now, lets use `MessagesState` with a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5306639-7e6a-44be-8471-8d2631701cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "# Node\n",
    "def tool_calling_llm(state: MessagesState):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_edge(\"tool_calling_llm\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8909771-7786-47d6-a53d-6bbc3b365737",
   "metadata": {},
   "source": [
    "If we pass in `Hello!`, the LLM responds without any tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "983e2487-c0a5-40a2-afbc-aa53ff49fefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hello!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi there! What can I do for you?\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Hello!\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588688b-efd9-4dbc-abf2-7903e3ef89ba",
   "metadata": {},
   "source": [
    "The LLM chooses to use a tool when it determines that the input or task requires the functionality provided by that tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe8b042-ecc8-426f-995e-cc1bbaf7cacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (3d029d10-dd4c-410e-adcf-bea5301565c9)\n",
      " Call ID: 3d029d10-dd4c-410e-adcf-bea5301565c9\n",
      "  Args:\n",
      "    b: 3.0\n",
      "    a: 2.0\n"
     ]
    }
   ],
   "source": [
    "messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 2 and 3\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnLangGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
