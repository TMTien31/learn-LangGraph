{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible. \n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independently of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e48f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "gemini_v25 = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0, api_key=GEMINI_API_KEY)\n",
    "\n",
    "gemini_v20 = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\", temperature=0, api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce315c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langgraph is a framework built on top of Langchain that allows you to build **stateful, multi-actor, and graph-based applications** using Large Language Models (LLMs). Think of it as a way to orchestrate complex LLM workflows, allowing you to chain together different LLM calls, tools, and other components in a structured and manageable way.\\n\\nHere\\'s a breakdown of what that means and why it\\'s useful:\\n\\n**Key Concepts:**\\n\\n*   **Graph-Based:** Langgraph uses a graph structure to define the flow of your application.  Nodes in the graph represent different components (e.g., an LLM call, a tool, a data processing step), and edges represent the connections and data flow between them. This visual and structured approach makes it easier to understand, debug, and modify complex workflows.\\n*   **Stateful:** Unlike some simpler LLM chaining approaches, Langgraph allows you to maintain state throughout the entire execution of the graph. This means you can store and access information (e.g., conversation history, intermediate results) across different nodes in the graph. This is crucial for building applications like chatbots or agents that need to remember past interactions.\\n*   **Multi-Actor:** Langgraph supports the concept of \"actors\" or \"agents\" within your graph. Each actor can have its own role, tools, and LLM configuration. This enables you to build applications where different LLMs or components collaborate to achieve a common goal. For example, you could have one actor responsible for understanding user input, another for generating a response, and a third for accessing external data.\\n*   **Asynchronous Execution:** Langgraph is designed for asynchronous execution, which means it can handle multiple tasks concurrently. This improves performance and responsiveness, especially for applications that involve long-running operations like LLM calls or API requests.\\n*   **Built on Langchain:** Langgraph leverages the existing Langchain ecosystem. You can easily integrate Langchain\\'s components like LLMs, chains, tools, and agents into your Langgraph applications.\\n\\n**Why Use Langgraph?**\\n\\n*   **Complex Workflows:**  It\\'s ideal for building applications that require intricate logic and multiple steps, such as:\\n    *   **Chatbots and Conversational Agents:**  Managing conversation history, handling user intent, and generating responses.\\n    *   **Automated Workflows:**  Automating tasks that involve multiple LLM calls, data processing, and tool usage.\\n    *   **Agent-Based Systems:**  Creating systems where multiple LLMs or agents collaborate to solve a problem.\\n*   **State Management:**  Easily maintain and access state throughout the entire workflow.\\n*   **Modularity and Reusability:**  The graph structure promotes modularity, making it easier to reuse and modify components.\\n*   **Scalability:**  Asynchronous execution and the graph structure can help you build more scalable applications.\\n*   **Debugging and Monitoring:**  The structured nature of Langgraph makes it easier to debug and monitor your applications.\\n\\n**Example Use Cases:**\\n\\n*   **Building a chatbot that can answer questions, access external data, and perform actions.**\\n*   **Creating an automated summarization tool that can summarize long documents and extract key information.**\\n*   **Developing an agent that can research a topic, write a report, and generate a presentation.**\\n*   **Building a system that can automate customer support tasks.**\\n\\n**In Summary:**\\n\\nLanggraph is a powerful framework for building sophisticated LLM-powered applications. It provides a structured, stateful, and graph-based approach to orchestrating complex workflows, making it easier to build, manage, and scale your LLM-based projects. If you\\'re looking to go beyond simple LLM chains and build more complex and interactive applications, Langgraph is definitely worth exploring.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run--adf51011-8b24-44f7-acc6-cd556c1eece1-0', usage_metadata={'input_tokens': 7, 'output_tokens': 797, 'total_tokens': 804, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini_v20.invoke(\"hello, what is Langgraph?\")\n",
    "response  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a29c4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Langgraph is a framework built on top of Langchain that allows you to build **stateful, multi-actor, and graph-based applications** using Large Language Models (LLMs). Think of it as a way to orchestrate complex LLM workflows, allowing you to chain together different LLM calls, tools, and other components in a structured and manageable way.\n",
       "\n",
       "Here's a breakdown of what that means and why it's useful:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Graph-Based:** Langgraph uses a graph structure to define the flow of your application.  Nodes in the graph represent different components (e.g., an LLM call, a tool, a data processing step), and edges represent the connections and data flow between them. This visual and structured approach makes it easier to understand, debug, and modify complex workflows.\n",
       "*   **Stateful:** Unlike some simpler LLM chaining approaches, Langgraph allows you to maintain state throughout the entire execution of the graph. This means you can store and access information (e.g., conversation history, intermediate results) across different nodes in the graph. This is crucial for building applications like chatbots or agents that need to remember past interactions.\n",
       "*   **Multi-Actor:** Langgraph supports the concept of \"actors\" or \"agents\" within your graph. Each actor can have its own role, tools, and LLM configuration. This enables you to build applications where different LLMs or components collaborate to achieve a common goal. For example, you could have one actor responsible for understanding user input, another for generating a response, and a third for accessing external data.\n",
       "*   **Asynchronous Execution:** Langgraph is designed for asynchronous execution, which means it can handle multiple tasks concurrently. This improves performance and responsiveness, especially for applications that involve long-running operations like LLM calls or API requests.\n",
       "*   **Built on Langchain:** Langgraph leverages the existing Langchain ecosystem. You can easily integrate Langchain's components like LLMs, chains, tools, and agents into your Langgraph applications.\n",
       "\n",
       "**Why Use Langgraph?**\n",
       "\n",
       "*   **Complex Workflows:**  It's ideal for building applications that require intricate logic and multiple steps, such as:\n",
       "    *   **Chatbots and Conversational Agents:**  Managing conversation history, handling user intent, and generating responses.\n",
       "    *   **Automated Workflows:**  Automating tasks that involve multiple LLM calls, data processing, and tool usage.\n",
       "    *   **Agent-Based Systems:**  Creating systems where multiple LLMs or agents collaborate to solve a problem.\n",
       "*   **State Management:**  Easily maintain and access state throughout the entire workflow.\n",
       "*   **Modularity and Reusability:**  The graph structure promotes modularity, making it easier to reuse and modify components.\n",
       "*   **Scalability:**  Asynchronous execution and the graph structure can help you build more scalable applications.\n",
       "*   **Debugging and Monitoring:**  The structured nature of Langgraph makes it easier to debug and monitor your applications.\n",
       "\n",
       "**Example Use Cases:**\n",
       "\n",
       "*   **Building a chatbot that can answer questions, access external data, and perform actions.**\n",
       "*   **Creating an automated summarization tool that can summarize long documents and extract key information.**\n",
       "*   **Developing an agent that can research a topic, write a report, and generate a presentation.**\n",
       "*   **Building a system that can automate customer support tasks.**\n",
       "\n",
       "**In Summary:**\n",
       "\n",
       "Langgraph is a powerful framework for building sophisticated LLM-powered applications. It provides a structured, stateful, and graph-based approach to orchestrating complex workflows, making it easier to build, manage, and scale your LLM-based projects. If you're looking to go beyond simple LLM chains and build more complex and interactive applications, Langgraph is definitely worth exploring."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a7cf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(tavily_api_key = TAVILY_API_KEY, max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - Analytics Vidhya',\n",
       "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of what’s possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) – based AI agents.\\n It views agent Objective Points about LangGraph and workflows as cyclic graph topologies, allowing for more variable and nuanced agent behaviors than linear execution models. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents.',\n",
       "  'score': 0.947386},\n",
       " {'title': 'What is LangGraph? - IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "  'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.',\n",
       "  'score': 0.94608605},\n",
       " {'title': \"Introduction to LangGraph: A Beginner's Guide - Medium\",\n",
       "  'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "  'content': 'LangGraph is a powerful tool for building stateful, multi-actor applications with Large Language Models (LLMs). It extends the LangChain library, allowing you to coordinate multiple chains (or actors) across multiple steps of computation in a cyclic manner. In this article, we’ll introduce LangGraph, walk you through its basic concepts, and share some insights and common points of confusion for beginners.\\n\\n## What is LangGraph? [...] ## Conclusion\\n\\nLangGraph is a versatile tool for building complex, stateful applications with LLMs. By understanding its core concepts and working through simple examples, beginners can start to leverage its power for their projects. Remember to pay attention to state management, conditional edges, and ensuring there are no dead-end nodes in your graph. Happy coding!\\n\\n## Sign up to discover human stories that deepen your understanding of the world.\\n\\n## Free\\n\\nDistraction-free reading. No ads. [...] LangGraph is a library built on top of LangChain, designed to add cyclic computational capabilities to your LLM applications. While LangChain allows you to define chains of computation (Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to add cycles, enabling more complex, agent-like behaviors where you can call an LLM in a loop, asking it what action to take next.\\n\\n## Key Concepts',\n",
       "  'score': 0.9224337}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnLangGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
